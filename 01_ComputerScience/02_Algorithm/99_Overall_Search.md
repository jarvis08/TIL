# Overall of Searching Algorithms

- O(`n`), 선형 시간, Linear Time 
  - 순차 탐색
- O(`nlogn`), 로그 선형 시간, Log-Linear time
- O(`n^2`), 제곱 시간, Quadratic time 
  - 최소 신장 트리- 프림 Prim
  - 최소 신장 트리- 크루스칼 Kruscal
  - 다익스트라, 두 정점 간의 최단 거리 구하기
- O(`n^3`), 세제곱 시간, Cubic time 
  - 플로이드 - 워셜, 모든 정점과 연결하는 최단거리 구하기에 사용되며, DP를 활용
- O(`2^n`), 지수 시간, Exponential time 
  - 부분집합 구하기, 배낭문제, 순열, TSP
  - 근사 알고리즘, 인공지능으로의 해결이 요구됨

<br>

<br>

## 순차 탐색, Linear Search

찾고자 하는 레코드가 나타날 때까지 차례로 비교하면서 순차적으로 검색을 수행한다.

<br><br>

## 이진 탐색, Binary Search

- 중앙값은 루트에 있으며, 파일의 중앙에서부터 탐색한다.
- 정렬된 상태의 배열을 정 가운데 index와 찾고자 하는 값을 비교하여 값을 찾아내는 방식
- 이진 탐색을 위한 트리는 루트의 중앙값을 시작으로 왼쪽에는 부모노드 보다 작은 수가 저장되고, 오른쪽은 큰 수가 저장됨
- 찾고자 하는 수가 비교하는 노드보다 작으면 비교 노드의 왼쪽 자식노드로 가서 비교하고 크면 오른쪽 자식노드로 가서 비교하며, 이러한 과정을 반복하며 찾아나감
- 하지만, 정렬되지 않는 배열에 적용할 수 없다는 단점을 가진다.

<br><br>

## 피보나치 탐색, Fibonacci Search

나눗셈을 사용하지 않고 덧셈과 뺄셈만 사용

나눗셈이 덧셈이나 뺄셈보다 더 많은 시간 소요

- 평균 효율이 이진탐색 보다 좋음

<br><br>

## AVL 트리

- 원소의 삽입과 삭제 연산 시간도 짧으면서 검색 시간이 을 갖는 2-원 탐색 트리
- 왼쪽 서브트리와 오른쪽 서브트리의 높이의 차가 1이하인 2-원 탐색 트리
- 노드의 균형 인수가 ۫이하이면 그 노드는 AVL 성질을 만족하고 ۬이상이면 AVL 성질을 만족하지 못함

<br>

<br>

<br>

# Hash Table

`hash`는 내부적으로 `배열`을 사용하여 데이터를 저장하기 때문에 빠른 검색 속도를 갖는다. 배열을 사용하기 때문에 특정한 값을 Search 하는데 데이터 고유의 `인덱스`로 접근하게 되며, collision이 발생했을 때를 제외하면 average case 에 대하여 시간 복잡도가 O(`1`)이다. Collision 해결이 쉽지 않은 이유는 이 인덱스로 사용되는 `key`값이 불규칙하기 때문이다.

**특별한 알고리즘을 이용하여** 저장할 데이터와 연관된 **고유한 숫자를 만들어 낸 뒤** 이를 인덱스로 사용한다. 특정 데이터가 저장되는 인덱스는 그 데이터 만의 고유한 위치이기 때문에, 삽입/삭제 연산 시에도 다른 데이터를 고려하지 않아도 된다.

해시 테이블의 목적인 이미 저장되어 있는 정보를 빠르게 탐색하는 것이며, 대략적인 설계 과정은 다음과 같다.

1. 특정 해시 함수(Hash Function)를 이용하여 유일한 16진수 숫자인 key(index)값으로 해싱
2. 해싱한 16진수를 키로 사용하는 해시 테이블(Hash Table)에 값을 저장

해시 테이블에서 정보를 탐색할 때에도 유사한 과정을 거친다.

1. 자료를 저장할 때 사용했을 때와 같은 해시 함수를 사용하여 해시 값을 생성
2. 해시 테이블에서 검색

<br>

<br>

## H**ash Function**

위에서 언급한 '**특별한 알고리즘**'을 `hash method` 또는 `해시 함수(hash function)`라고 하며, 이 메소드에 의해 반환된 데이터의 고유 숫자 값을 `hash code`라고 한다. 저장되는 값들의 key 값을 `hash function`을 통해 **작은 범위의 값들로** 바꿔준다.

하지만 어설픈 `hash function`을 통해서 key 값들을 결정한다면 동일한 값이 도출될 수가 있다. 동일한 key 값에 복수 개의 데이터가 하나의 테이블에 존재할 때, 이를 `Collision` 이라고 한다.

<br>

### **좋은 Hash Function의 조건**

일반적으로 좋은 `hash function`은 키의 일부분이 아닌, 키 전체를 참조하여 해쉬 값을 만들어 낸다. 하지만 좋은 해쉬 함수는 키가 어떤 특성을 가지고 있느냐에 따라 달라진다.

`hash function`을 무조건 1:1 관계로 만드는 것보다는 **Collision 을 최소화**하는 방향으로 설계하고, '**발생하는 Collision 에 대비해 어떻게 대응할 것인가**'를 고려하는 것이 더 중요하다. 1:1 대응이 되도록 만드는 것이 거의 불가능에 가까우며, 그러한 `hash function`를 만들더라도 이는 일반적인 배열과 유사하고, 메모리를 지나치게 차지하게 된다.

해싱 테이블 내의 버킷 주소로 변환하며, 주소가 특정 주소에 편향되지 않도록 하고, 편향된 주소로 해싱된 자료들이 오버플로우를 발생시키지 않도록 하는 것이 중요하다.

<br>

### Hash Function의 종류

1. 제산 잔여 해싱

   나머지 연산자(%)를 사용하여 키를 어떤 정해진 수로 나누고 나머지를 버킷 주소로 사용

   가장 큰 소수를 제수로 사용

2. 중간 제곱 해싱

   키 값을 제곱한 후에 그 결과의 중간에서 미리 정해진 자리의 숫자를 뽑아내어 버킷 주소로 사용

3. 폴딩 해싱

   키 값을 주소와 같은 자리수를 갖는 몇 개의 부분으로 나눈 다음, 그 부분들을 서로 더하여 주소를 만들어 내는 방법

   - 이동 폴딩 : 나누어진 부분의 값을 그대로 더하는 방법
   - 경계 폴딩 : 마치 종이를 접듯이 부분을 경계에서 겹친 후, 만나게 되는 수를 더하는 방법

4. 숫자분석 해싱

   저장할 자료를 미리 알고 있는 경우에 유용하게 활용

   키 값의 분포를 활용하여 적절하게 배치

<br>

<br>

## Collision, **Conflict 해결하기**

기본적인 두 가지 방법은 다음과 같으며, 기타 다른 방법들도 아래의 두 방식을 응용한다.

- 개방 주소법

  비어있는 버킷을 찾아 자료를 저장하는 방법

- 폐쇄 주소법

  각 버킷마다 개별적인 연결 리스트 구조를 할당하는 방식

<br>

### Open Address, 개방 주소법

해시 충돌이 발생했을 때 **다른 해시 버킷에 해당 자료를 삽입하는 방식**이다. **충돌**은 삽입하려는 해시 버킷이 이미 사용 중일 때 발생하며, **버킷은**데이터를 저장하기 위한 공간이다.

**공개 주소 방식**이라고도 불리는 이 알고리즘은 Collision이 발생하면 데이터를 저장할 장소를 찾기 시작한다. **Worst Case**의 경우 비어있는 버킷을 찾지 못하고 탐색을 시작한 위치까지 되돌아오게 된다.

버킷을 찾는 과정에는 세 가지 방법이 있다.

1. Linear Probing

   비어있는 버킷을 찾을 때까지 순차적으로 탐색한다.

   1. 특정 Hash Function을 통해 얻어낸 index를 *hash(key)* 라고 한다.
   2. 만약 *data[hash]* 가 비어 있다면 저장하고 끝낸다.
   3. 비어 있지 않으며, *data[hash(key)+1]*을 계속해서 진행하여 비어 있는 곳에 저장 후 종료

2. Quadratic probing

   2차 함수를 이용하여 탐색할 위치를 찾는다.

   Clustering Problem으로 인해 Insertion 작업의 시간이 오래 걸릴 수 있다.

3. Double hashing probing

   하나의 해쉬 함수에서 충돌이 발생했을 때, 2차 해쉬 함수를 이용해 새로운 주소를 할당한다. 위의 두 가지 방법들에 비해 많은 연산량을 요구한다.

   - *Hash Function 1*과 *Hash Function 2*를 정의한다.

   - *Hash Function 1*을 통해 얻어낸 index가 비어있지 않다면,

     *Hash Function 2*를 통해 얻은 값을 index에 더한다.

<br>

### Separate Chaining, 분리 연결법

- Array가 하나 이상의 Entry를 가질 수 있는 Hashing 방법이다.
- Collision이 발생하면 해당 index에 새로운 Entry를 추가한다.

일반적으로 Separate Chaining이 Open Addressing 보다 빠르다. Open Addressing의 경우 해시 버킷을 채운 밀도가 높아질수록 Worst Case 발생 빈도가 더 높아지기 때문이다. 반면 Separate Chaining 방식의 경우 해시 충돌이 잘 발생하지 않도록 **보조 해시 함수**를 통해 조정할 수 있다면 Worst Case에 가까워 지는 빈도를 줄일 수 있다. Java 7 에서는 Separate Chaining 방식을 사용하여 HashMap을 구현하고 있다. Separate Chaining 방식에는 두 가지 구현 방식이 있다.

- **Linked List**

  각각의 버킷(bucket)들을 연결 리스트(Linked List)로 구현하고, Collision이 발생했을 때 해당 bucket의 list에 추가하는 방식이다. 연결 리스트의 특징을 그대로 이어받아 삭제 또는 삽입이 간단하다. 하지만 단점 또한 연결 리스트의 특성처럼 작은 데이터들을 저장할 때 오버헤드가 발생한다. 또 다른 특징으로, 버킷을 계속해서 사용하는 Open Address의 방식에 비해 테이블의 확장을 늦출 수 있다.

- **Red-Black Tree**

  기본적인 알고리즘은 Separate Chaining 방식과 동일하며 연결 리스트 대신 트리를 사용하는 방식이다. 연결 리스트와 트리 중 선택하는 기준은 **하나의 해시 버킷에 할당된 key-value 쌍의 개수**이다. 트리는 기본적으로 메모리 사용량이 많기 때문에 데이터의 개수가 적다면 연결 리스트를 사용하는 것이 좋다. 왜냐하면 데이터 개수가 적을 때의 Worst Case를 살펴보면 트리와 연결 리스트의 성능 차이가 거의 없다. 따라서 메모리 측면을 봤을 때 데이터 개수가 적을 때에는 연결 리스트를 사용한다.

'**데이터가 적다는 것은 얼마나 적다는 것을 의미하는가'의**기준은 하나의 해시 버킷에 할당된 key-value 쌍의 개수이다. 이 키-값 쌍의 개수가 6 개, 8 개를 기준으로 결정한다. 기준이 두 개인 것이 이상하게 느껴질 수 있다. 7 은 어디로 갔는가? 연결 리스트의 기준과 트리의 기준을 6 과 8 로 설정한 것은, 변경하는데 소요되는 비용을 줄이기 위함이다.

변경 비용에 대한 예시는 다음과 같다. 해시 버킷에 **6 개** 의 key-value 쌍이 들어있었으며, 하나의 값이 추가되었다. 만약 기준이 6 과 7 이라면 자료구조를 연결 리스트에서 트리로 변경해야 한다. 그러던 중 하나의 값이 삭제된다면, 다시 트리에서 연결 리스트로 자료 구조를 변경해야 한다. 각각의 자료 구조로 변경되는 기준값이 1이므로 Switching 비용이 너무 크다. 따라서 2라는 여유를 남겨두고 기준을 잡는 것이며, 데이터의 개수가 6 개에서 7 개로 증가했을 때에는 연결 리스트의 자료 구조를 사용하고 있을 것이며, 8개에서 7개로 감소했을 때에는 트리의 자료 구조를 취하고 있을 것이다.

<br>

### [**Open Address] vs [Separate Chaining]**

두 방식 모두 Worst Case 에서 시간 복잡도가 O(`M`)이다. 하지만 `Open Address`방식은 연속된 공간에 데이터를 저장하기 때문에 `Separate Chaining`에 비해 **캐시 효율**이 높다. 따라서 데이터의 개수가 충분히 적다면 `Open Address`방식이 `Separate Chaining`보다 더 성능이 좋다. 하지만 동일한 이유로, `Separate Chaining` 방식은 테이블의 확장을 보다 늦출 수 있다.

<br>

### **보조 해시 함수**

보조 해시 함수(supplement hash function)의 목적은 `key`의 해시 값을 변형하여 해시 충돌 가능성을 줄이는 것이다. `Separate Chaining` 방식을 사용할 때 함께 사용되며, Worst Case에 가까워지는 경우를 줄일 수 있다.

<br>

### 해시 버킷 동적 확장, Resize**

해시 버킷의 개수가 적다면 메모리 사용을 아낄 수 있지만, 해시 충돌로 인해 성능 손실이 발생한다. 그래서 Hash Map 은 **key-value 쌍 데이터 개수가 일정 개수 이상**이 되면 해시 **버킷의 개수를 두 배로 늘려**충돌로 인한 성능 손실 문제를 어느 정도 해결할 수 있다. 해시 버킷 크기를 두 배로 확장하는 **임계점**은 **현재 데이터 개수가 해시 버킷 개수의 75%**가 될 때이다. `0.75`라는 숫자는 `load factor`라고 불린다.

<br>

<br>

<br>

# REFERENCE

- [JaeYeopHan's Github](https://github.com/JaeYeopHan/Interview_Question_for_Beginner/tree/master/DataStructure)

  Hash