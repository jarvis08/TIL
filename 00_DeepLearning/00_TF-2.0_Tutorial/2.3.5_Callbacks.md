# 2.3.5 Callbacks

## 1. 콜백(Callback)이란

### 1.1 콜백의 정의

콜백 함수의 정의는 다음과 같습니다.

```
어떤 함수에 전달된 후, 그 함수가 실행되는 동안 특정 조건을 충족하면 호출되는 함수
```

텐서플로(TensorFlow)에서의 콜백 또한 크게 다르지 않으며, 다양한 방법으로 학습하는 모델을 모니터링하고 조작할 수 있습니다. 텐서플로에는 콜백 함수를 두 가지 방법으로 사용할 수 있습니다.

- 제공되는 내장 콜백 사용
- `tf.keras.callbacks.Callback`를 상속하여 사용자 정의(Custom) 콜백 제작

현재 챕터에서는 내장되어 있는 콜백들에 대해 알아보겠습니다.

<br>

### 1.2 내장 콜백의 종류

콜백들은 종류 별로 클래스 형태로 제작되어 있으며, 매개변수를 지정할 수 있으며, 메서드를 실행할 수 있습니다.

| 콜백 종류               | 내용                                                      |
| ----------------------- | --------------------------------------------------------- |
| `History`               | `History` 객체에 발생하는 특징적인 상황을 기록            |
| `BaseLogger`            | 에포크의 평균을 누적하며 콜백                             |
| `EarlyStopping`         | 모니터링하던 대상의 성능 향상이 멈추면 학습을 중단        |
| `LearningRateScheduler` | 학습률(Learning Rate)을 동적으로 조정                     |
| `ReduceLROnplateau`     | 성능 평가 지표의 성능 향상이 멈췄을 때 학습률 감소를 적용 |
| `ModelCheckpoint`       | 매 에포크마다 모델을 저장                                 |
| `TensorBoard`           | 텐서보드(TensorBoard)로 시각화 하는 기능을 사용           |
| `LambdaCallback`        | 간단한 사용자 정의 콜백을 즉시 생성                       |
| `ProgbarLogger`         | 성능 평가 지표(metrics)를 stdout으로 출력                 |
| `TerminateOnNaN`        | `NaN` 손실이 발생했을 때 학습을 종료                      |
| `RemoteMonitor`         | 서버에 이벤트를 전송                                      |
| `CSVLogger`             | 에포크의 결과를 csv 파일로 전송                           |
| `Callback`              | 새로운 콜백을 제작할 수 있는 클래스                       |

콜백은 사용자가 학습 도중, 혹은 학습 후 돌려받고 싶은 모델의 피드백을 정의합니다. 따라서 사용자  별, 그리고 상황 별로 필요한 콜백이 다릅니다. 다행히 콜백의 기능들은 그 이름에서부터 기능을 쉽게 알 수 있습니다.

콜백 중에서도 기본이 되는 콜백, 혹은 자주 사용되는 콜백들부터 차근차근 알아보겠습니다.

<br>

<br>

## 2. History 및 콜백 공통 메서드

각각의 콜백 클래스들은 다음과 같은 공통된 메서드들을 보유하고 있습니다.

`on_batch_begin`, `on_batch_end`, `on_batch_end`, `on_epoch_begin`, `on_epoch_end`, `on_predict_batch_begin`, `on_predict_batch_end`, `on_predict_begin` ...

위의 메서드들은 학습 도중 어느 작업을 하던 중, 어느 시점에 사용자가 요청한 콜백을 점검할 것인지 결정합니다. 예를들어 `on_epoch_end`와 정확도가 `0.99` 이상일 때 학습을 중단하도록 콜백을 지정했다면, 한 에포크가 종료될 때마다 정확도가 `0.99` 이상이되는가를 점검 후 조건 만족 시 학습을 종료합니다.

`History` 클래스는 학습, 검증, 테스트 과정에서 측정되는 지표들을 저장하기 위해 사용합니다.

<br>

<br>

## 3. BaseLogger

베이스 로거(BaseLogger)는 에포크(epoch) 별 측정 지표(metrics)를 누적합니다. 콜백의 이름이 베이스 로거인 이유는 모든 케라스 모델들에 자동으로 적용되기 때문입니다. 따라서 `fit`과 같은 학습 메서드에 베이스 로거 콜백을 사용하라고 지시해줘야 할 필요가 없습니다. 로그는 `on_epoch_end` 시점에 `History` 객체 형태로 기록됩니다.

<br>

### 3.1 매개변수

```python
__init__(stateful_metrics=None)
```

- `stateful_metrics`: 이 매개변수에 기록한 Iterable(리스트 등)에 해당하는 측정 지표들은 기록하지 않습니다.

<br>

### 3.2 예시

`fit`과 같은 학습 메서드의 실행 결과를 임의의 변수에 저장한 후, 그 변수의 `history`를 호출합니다.

코드

```python
from __future__ import absolute_import, division, print_function, unicode_literals
import tensorflow as tf
from tensorflow import keras
import numpy as np

fashion_mnist = keras.datasets.fashion_mnist
(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()
class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal',
 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot']
 
train_images = train_images / 255.0
test_images = test_images / 255.0

model = keras.Sequential([
    keras.layers.Flatten(input_shape=(28, 28)),
    keras.layers.Dense(128, activation=tf.nn.relu),
    keras.layers.Dense(10, activation=tf.nn.softmax)
])

model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

train_his = model.fit(train_images, train_labels, epochs=5, callbacks=None)
print(train_his.history)
```

결과

```
{'loss': [0.5007445385138194, 0.37360614700714745, 0.3342456784168879, 0.31103399897416434, 0.2948230089247227], 'acc': [0.8250167, 0.8647, 0.8793167, 0.88591665, 0.89155]}
```

<br>

<br>

## 4. EarlyStopping

모니터링하는 지표가 성장을 멈추면 학습을 중단합니다. 적절하게 고려된 조기 중단(Early Stopping)은 모델 학습에 좋은 영향을 미치는 경우가 많습니다. 우리는 정확히 모델이 얼마나 학습해야 하는지 알 수 없습니다. 학습 회수가 늘어날 수록 학습 데이터셋과 검증 데이터셋에 대한 모델의 정답률은 올라갈 수 있습니다. 하지만 지나친 학습/검증 데이터 학습은 모델의 **일반화**에 악영향을 미칠 수 있습니다. 일반화란 모델이 학습하지 않은 데이터에 대한 정답율을 높히는 작업입니다.

쉽게 사용할 수 있는 조기 중단의 시점은 테스트 데이터셋에 대한 정확도가 감소하는 시점입니다. 이를 포착하기 위해 검증 데이터셋(validation dataset)의 개념이 도입됐습니다. 테스트 데이터셋을 학습의 측정 지표로 사용하는 것 또한 결국 학습 자체에 영향을 미치는 것이므로, 테스트 데이터셋을 완전히 격리하고 검증 데이터셋을 학습 도중의 측정 데이터셋으로 사용합니다. 이렇게 분리하여 검증 데이터셋에 대한 측정 지표(metric)는 성능이 향상되고 있음을 말해주지만, 테스트 데이터셋에 대한 지표가 하락하고 있는 상황을 과적합(Overfitting)이라고 합니다. 우리는 학습을 조기 중단하여 이러한 상황을 회피해야 합니다.

<br>

### 4.1 매개변수

```python
__init__(
    monitor='val_loss',
    min_delta=0,
    patience=0,
    verbose=0,
    mode='auto',
    baseline=None,
    restore_best_weights=False
)
```

- `monitor`: 모니터 할 지표를 지정합니다.

- `min_delta`: 지정한 지표의 성능이 향상 중이라고 여기는 최소 변화량을 지정합니다.

- `patience`: `min_delta` 보다 작은 성장이 몇 회 반복되는 것까지 기다릴 것인지 지정합니다. 즉, `patience` 횟수 만큼 성장이 이루어지지 않는다면 학습을 중단합니다.

- `verbose`: 얼마나 자세히 로그를 보고할 것인가를 지정합니다.

- `mode`: 조기 중단을 측정하는 지표의 최소화를 목표로 하는지, 혹은 최대화를 목표로하는지 설정합니다. `"auto"`, `"min"`, `"max"` 세 가지 값 중 하나를 설정할 수 있습니다.
- `min`: 지표가 감소하는 방향으로 학습하는 것으로 인식합니다.
  
- `max`: 지표가 증가하는 방향으로 학습하는 것으로 인식합니다.
  
- `auto`: 지표의 이름에 따라 자동으로 설정됩니다.
  
- `baseline`: 설정하는 기준값 이상으로 향상되지 않는다면, 학습을 조기 중단합니다.

- `restore_best_weights`: 매 에포크 마다 가장 성능이 좋았던 가중치를 복구하여 설정합니다. `False`일 경우 가장 마지막 스텝에서 계산해낸 가중치를 사용합니다.

<br>

### 4.2 예시

500 에포크 학습을 진행하는데, 3회의 에포크 동안 정확도(`acc`)에서 성능 향상이 없다면 학습을 조기 중단합니다.

코드

```python
from __future__ import absolute_import, division, print_function, unicode_literals
import tensorflow as tf
from tensorflow import keras
import numpy as np

fashion_mnist = keras.datasets.fashion_mnist
(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()
class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal',
 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot']
 
train_images = train_images / 255.0
test_images = test_images / 255.0

model = keras.Sequential([
    keras.layers.Flatten(input_shape=(28, 28)),
    keras.layers.Dense(128, activation=tf.nn.relu),
    keras.layers.Dense(10, activation=tf.nn.softmax)
])

model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

# 조기 중단 콜백을 설정합니다.
callback = tf.keras.callbacks.EarlyStopping(monitor='acc', patience=3)
# 학습 메서드인 fit을 사용하며, 콜백 매개변수에 위에서 설정한 콜백을 지정합니다.
model.fit(train_images, train_labels, epochs=500, callbacks=[callback])
```

결과

```
Epoch 50/500
60000/60000 [==============================] - 2s 26us/sample - loss: 0.1006 - acc: 0.9620
Epoch 51/500
60000/60000 [==============================] - 2s 26us/sample - loss: 0.0987 - acc: 0.9627
Epoch 52/500
60000/60000 [==============================] - 2s 26us/sample - loss: 0.0980 - acc: 0.9627
Epoch 53/500
60000/60000 [==============================] - 2s 25us/sample - loss: 0.0995 - acc: 0.9621
Epoch 54/500
60000/60000 [==============================] - 2s 25us/sample - loss: 0.0937 - acc: 0.9653
Epoch 55/500
60000/60000 [==============================] - 2s 26us/sample - loss: 0.0933 - acc: 0.9648
Epoch 56/500
60000/60000 [==============================] - 2s 26us/sample - loss: 0.0926 - acc: 0.9647
Epoch 57/500
60000/60000 [==============================] - 2s 25us/sample - loss: 0.0929 - acc: 0.9648
학습 종료
```

57 에포크 학습 후 조기 중단합니다.

<br>

<br>

## 5. LearningRateScheduler

모델 학습의 주요 파라미터(Hyper Parameter) 중 하나인 학습률(Learning Rate)을 동적으로 관리합니다. 학습률을 관리하는 것은 모델 학습을 최적화 하는 기법들 중 하나입니다. 주로 큰 값의 학습률로 학습을 시작하여 점차 줄여나아가는 형태로 관리합니다.

<br>

### 5.1 매개변수

```python
__init__(
    schedule,
    verbose=0
)
```

- `schedule`: 에포크의 인덱스를 입력값으로 취하며, 새로운 학습률을 반환하는 함수를 지정합니다.

- `verbose`: `0`으로 설정할 시 아무런 피드백을 하지 않으며, `1`일 시 메세지를 업데이트 합니다.

<br>

### 5.2 예시

아래의 `scheduler` 함수는 `10` 에포크까지는` 0.001`의 학습률을 유지하다가, `11` 에포크 부터는 기하급수적으로 감소합니다.

```python
def scheduler(epoch):
  if epoch < 10:
    return 0.001
  else:
    return 0.001 * tf.math.exp(0.1 * (10 - epoch))

callback = tf.keras.callbacks.LearningRateScheduler(scheduler)
model.fit(data, labels, epochs=100, callbacks=[callback],
          validation_data=(val_data, val_labels))
```

<br>

<br>

## 6. ReduceLROnplateau

측정 수단(metric)의 성장을 체크하여, `patience` 값 동안 성장이 멈추면 학습률을 `factor` 만큼 감소시킵니다.

<br>

### 6.1 매개변수

```python
__init__(
    monitor='val_loss',
    factor=0.1,
    patience=10,
    verbose=0,
    mode='auto',
    min_delta=0.0001,
    cooldown=0,
    min_lr=0,
    **kwargs
)
```

- `monitor`: 모니터링 할 지표를 지정합니다.

- `factor`: 기존 조정할 학습률에 `factor` 를 적용하여 새로운 학습률을 생성합니다.

  `새 학습률 = (기존 학습률) * factor`

- `patience`: 몇 회의 에포크 동안 성능 향상이 없을 시 학습률을 감소시킬 것인지 결정합니다.

- `verbose`: `0`으로 설정할 시 아무런 피드백을 하지 않으며, `1`일 시 메세지를 업데이트 합니다.

- `mode`: 측정하는 지표의 최소화를 목표로 하는지, 혹은 최대화를 목표로하는지 설정합니다. `"auto"`, `"min"`, `"max"` 세 가지 값 중 하나를 설정할 수 있습니다.

  - `min`: 지표가 감소하는 방향으로 학습하는 것으로 인식합니다.

  - `max`: 지표가 증가하는 방향으로 학습하는 것으로 인식합니다.

  - `auto`: 지표의 이름에 따라 자동으로 설정됩니다.

- `min_delta`: 학습률을 감소시키기 전, 최적 상태임을 판단하는데 사용되는 임계치입니다.

- `cooldown`: 학습률 감소 후, 몇 회의 에포크 동안 학습률 감소 작업을 진행하지 않고 대기할 것인지 결정합니다.

- `min_lr`: 학습률의 최소값을 설정합니다.

<br>

### 6.2 예시

평가 지표 중 정확도를 참고하여 학습률을 감소시킵니다.

코드

```python
reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(
    monitor='acc', verbose=1, factor=0.2, 
    patience=5, min_lr=0.001
)
model.fit(train_images, train_labels, epochs=500, callbacks=[reduce_lr])
```

결과

```
Epoch 106/500
60000/60000 [==============================] - 2s 26us/sample - loss: 0.0494 - acc: 0.9814
Epoch 107/500
60000/60000 [==============================] - 2s 27us/sample - loss: 0.0493 - acc: 0.9822
Epoch 108/500
59328/60000 [============================>.] - ETA: 0s - loss: 0.0500 - acc: 0.9813
Epoch 00108: ReduceLROnPlateau reducing learning rate to 0.001.
60000/60000 [==============================] - 2s 27us/sample - loss: 0.0502 - acc: 0.9812
Epoch 109/500
60000/60000 [==============================] - 2s 26us/sample - loss: 0.0505 - acc: 0.9815
```

학습 도중, 108 에포크에서 학습률이 0.001로 감소했습니다.

<br>

<br>

## 7. ModelCheckpoint

매 에포크마다 학습 실패가 일어나지 않는 한 모델을 `hdf5` 형식으로 저장하며, `filepath` 매개변수를 통해 저장하는 내용의 표현 단위를 딕셔너리 형태로 지정할 수 있습니다. 또한 파일명을 사용자가 원하는대로 지정하여, 학습 도중 혹은 학습 이후 확인하기 용이하도록 설정할 수 있습니다.

```python
checkPoint = tf.keras.callbacks.ModelCheckpoint(
        filepath='./checkpoints/fashionMNIST.epoch5.h5',
        monitor='acc',
        save_best_only=True
)
model.fit(train_images, train_labels, epochs=5, callbacks=[checkPoint])
```

위 코드 블록의 예시코드는 에포크와 검증의 손실 함수 표현 단위를 `02d`와 `2f`로 제한합니다.

<br>

### 7.1 매개변수

```python
__init__(
    filepath,
    monitor='val_loss',
    verbose=0,
    save_best_only=False,
    save_weights_only=False,
    mode='auto',
    save_freq='epoch',
    load_weights_on_restart=False,
    **kwargs
)
```

- `filepath`: `string` 자료형으로 모델 파일을 저장할 경로를 설정합니다.
- `monitor`: 모니터링 할 지표를 설정합니다.
- `verbose`: `0`으로 설정할 시 아무런 피드백을 하지 않으며, `1`일 시 메세지를 업데이트 합니다.
- `save_best_only`: `True`일 경우, 가장 최근에 관찰된 지표(`monitor`에서 지정)의 최대값을 덮어쓰지 않고 유지합니다.
- `mode`: 측정하는 지표의 최소화를 목표로 하는지, 혹은 최대화를 목표로하는지 설정합니다. `"auto"`, `"min"`, `"max"` 세 가지 값 중 하나를 설정할 수 있습니다.  `save_best_only=True`일 경우 지표가 최대/혹은 최소일 경우에만 저장합니다.
  - `min`: 지표가 감소하는 방향으로 학습하는 것으로 인식합니다.
  - `max`: 지표가 증가하는 방향으로 학습하는 것으로 인식합니다.
  - `auto`: 지표의 이름에 따라 자동으로 설정됩니다.
- `save_weights_only`: `True`일 경우 모델을 저장할 때 가중치 값만을 저장합니다.
- `save_freq`: 기본값인 `epoch`로 설정할 경우 매 에포크마다 모델을 저장합니다. 기본값 대신 정수값을 사용한다면, 정수값 만큼의 배치마다 저장합니다.
- `load_weights_on_restart`: `True`로 설정한다면 `fit` 메서드가 실행될 때 지정된 `filepath`에서 이전의 체크포인트가 있는지 확인하고 불러옵니다. 만약 파일이 없다면 무시하고 새로운 학습을 시작합니다. 모델 체크포인트 파일에는 학습 작업 환경이 함께 포함되어 있으므로, 만약 `workers`와 같은 작업 환경이 현재 환경과 동일하지 않다면 `ValueError`가 발생합니다.

<br>

### 7.2 예시

`checkpoints`라는 디렉토리 안에 `fashionMNIST.epoch5.h5`라는 이름을 가진 모델 체크포인트 파일을 저장시킵니다.

```python
checkPoint = tf.keras.callbacks.ModelCheckpoint(
        filepath='./checkpoints/fashionMNIST.epoch5.h5',
        monitor='acc',
        save_best_only=True
)
model.fit(train_images, train_labels, epochs=5, callbacks=[checkPoint])
```

<br>

<br>

## 8. 기타 콜백들

### 8.1 TensorBoard

텐서보드(TensorBoard)는 학습 과정에 대한 강력한 시각화 도구입니다. 시각화 내용은 측정 지표가 요약된 도표를 포함합니다. 현재 챕터에서는 간단한 콜백 방식만 알아본 후, 챕터 '3.4.1 Tensorboard' 에서 자세히 다루도록 하겠습니다.

생성된 텐서보드를 실행하려면 `tensorboard --logdir 파일의경로` 명령어를 cmd/bash에 입력합니다. 그 후 사용한 CLI에서 알려주는 웹 주소로 접속합니다.

```python
tensorboard = tf.keras.callbacks.TensorBoard(
    log_dir='./tensorboard'
)
model.fit(train_images, train_labels, epochs=5, callbacks=[tensorboard])
```

```shell
$ tensorboard --logdir tensorboard
```

<br>

### 8.2 LambdaCallback

`lambda`를 사용하여 간단한 사용자 콜백을 제작합니다. 간단하게 `에포크/배치/학습과정`의 `시작부/종료부`에 원하는 피드백을 받을 수 있도록 합니다.

아래 코드 블록에는 두 가지 람다콜백이 사용됩니다. 하나(`batch_print`)는  배치가 시작될 때 마다 몇 번째 배치인지 출력하며, 다른 하나(`json_logging`)는 에포크 별 손실을 `loss_log.json` 파일로 저장합니다.

```python
batch_print = tf.keras.callbacks.LambdaCallback(
    on_batch_begin=lambda batch,logs: print(batch)
)

import json
json_log = open('loss_log.json', mode='wt', buffering=1)
json_logging_callback = LambdaCallback(
    on_epoch_end=lambda epoch, logs: json_log.write(
        json.dumps({'epoch': epoch, 'loss': logs['loss']}) + '\n'),
    on_train_end=lambda logs: json_log.close()
)

model.fit(train_images, train_labels, epochs=5, callbacks=[lambdaCallback, json_logging_callback])
```

<br>

### 8.3 Callback

`keras.callbacks.Callback`을 상속한다면 제공되는 다른 콜백들 보다 하위 수준에서 조작할 수 있으며, 사용자가 원하는 콜백을 제작할 수 있습니다.

아래 코드 블록의 `CustomCallback` 클래스는 배치가 시작되기 전/후에 그 시작과 끝을 출력해주는 콜백에 대한 메서드들을 포함하며, `fit` 메서드에 그 클래스의 인스턴스를 생성하여 매개변수로 전달합니다.

```python
import datetime


class CustomCallback(tf.keras.callbacks.Callback):

  def on_train_batch_begin(self, batch, logs=None):
    print('Training: batch {} begins at {}'.format(batch, datetime.datetime.now().time()))

  def on_train_batch_end(self, batch, logs=None):
    print('Training: batch {} ends at {}'.format(batch, datetime.datetime.now().time()))

  def on_test_batch_begin(self, batch, logs=None):
    print('Evaluating: batch {} begins at {}'.format(batch, datetime.datetime.now().time()))

  def on_test_batch_end(self, batch, logs=None):
    print('Evaluating: batch {} ends at {}'.format(batch, datetime.datetime.now().time()))


model.fit(train_images, train_labels, epochs=5, callbacks=[CustomCallback()])
```

<br>

### 8.4 TerminateOnNaN

학습 도중 `NaN` 손실이 발생할 경우 학습을 종료합니다. `Nan`이 발생할 수 있는 경우의 가장 대표적인 예시는 학습률을 잘못 지정했을 때입니다. 학습 도중 학습률이 비정상적으로 상승하여 overshooting 될 수 있는데, 이 경우 손실 함수는 `NaN`을 반환하게 됩니다.

```python
model.fit(train_images, train_labels, epochs=5,
    callbacks=[tf.keras.callbacks.TerminateOnNaN])
```

<br>

### 8.5 RemoteMonitor

`requests` 라이브러리를 통해 HTTP POST 방식으로 JSON 파일을 전송합니다. 전송받는 타겟 서버(`root`)와 전송 할 대상(`path`)을 지정합니다.

```python
remoteMonitor = tf.keras.callbacks.RemoteMonitor(
    root='http://localhost:9000', path='/publish/epoch/end/', 
    field='data', headers=None, send_as_json=False
)
```

<br>

### 8.6 ProgbarLogger

stdout으로 측정 지표를 출력합니다. `count_mode` 매개변수에 `steps` 혹은 `samples`를 지정할 수 있는데, 이는 진행 막대를 통해 샘플의 카운팅을 표시할 것인지, 혹은 스텝을 표시할 것인지를 결정합니다. 기본값은 `samples`입니다.

코드

```python
progbar = tf.keras.callbacks.ProgbarLogger(count_mode='steps')
model.fit(train_images, train_labels, epochs=5, callbacks=[progbar])
```

결과

```shell
Epoch 1/5
Epoch 1/5
60000/60000 [==============================] - 2s 32us/sample - loss: 0.5007 - acc: 0.8248
Epoch 2/5
Epoch 2/5
60000/60000 [==============================] - 2s 31us/sample - loss: 0.3766 - acc: 0.8644
Epoch 3/5
Epoch 3/5
60000/60000 [==============================] - 2s 31us/sample - loss: 0.3384 - acc: 0.8773
Epoch 4/5
Epoch 4/5
60000/60000 [==============================] - 2s 31us/sample - loss: 0.3142 - acc: 0.8854
Epoch 5/5
Epoch 5/5
60000/60000 [==============================] - 2s 31us/sample - loss: 0.2962 - acc: 0.8913
```

<br>

### 8.7 CSVLogger

에포크의 결과를 csv 형태로 전송합니다. `String` 자료형으로 표현될 수 있는 모든 값들을 전송할 수 있으며, 1차원 배열과 같은 Iterable 또한 전송 가능합니다.

아래의 코드 블록은 csv 기록 형식으로 `csv.log`라는 log 파일과 `csv.csv`라는 csv 파일을 제작합니다.

```python
csv_logger = tf.keras.callbacks.CSVLogger('csv.log')
csv_logger2 = tf.keras.callbacks.CSVLogger('csv.csv')
model.fit(train_images, train_labels, epochs=5, callbacks=[csv_logger, csv_logger2])
```

