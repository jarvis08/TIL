# 2.3.5 Callbacks

## 1. 콜백(Callback)이란

### 1.1 콜백의 정의

콜백 함수의 정의는 다음과 같습니다.

```
어떤 함수에 전달된 후, 그 함수가 실행되는 동안 특정 조건을 충족하면 호출되는 함수
```

텐서플로(TensorFlow)에서의 콜백 또한 크게 다르지 않으며, 다양한 방법으로 학습하는 모델을 모니터링하고 조작할 수 있습니다. 텐서플로에는 콜백 함수를 두 가지 방법으로 사용할 수 있습니다.

- 제공되는 내장 콜백 사용
- `tf.keras.callbacks.Callback`를 상속하여 사용자 정의(Custom) 콜백 제작

현재 챕터에서는 내장되어 있는 콜백들에 대해 알아보겠습니다.

<br>

### 1.2 내장 콜백의 종류

콜백들은 종류 별로 클래스 형태로 제작되어 있으며, 매개변수를 지정할 수 있으며, 메서드를 실행할 수 있습니다.

| 콜백 종류               | 내용                                                      |
| ----------------------- | --------------------------------------------------------- |
| `History`               | `History` 객체에 발생하는 특징적인 상황을 기록            |
| `BaseLogger`            | 에포크의 평균을 누적하며 콜백                             |
| `EarlyStopping`         | 모니터링하던 대상의 성능 향상이 멈추면 학습을 중단        |
| `LearningRateScheduler` | 학습률(Learning Rate)을 동적으로 조정                     |
| `ReduceLROnplateau`     | 성능 평가 지표의 성능 향상이 멈췄을 때 학습률 감소를 적용 |
| `ModelCheckpoint`       | 매 에포크마다 모델을 저장                                 |
| `TensorBoard`           | 텐서보드(TensorBoard)로 시각화 하는 기능을 사용           |
| `LambdaCallback`        | 간단한 사용자 정의 콜백을 즉시 생성                       |
| `ProgbarLogger`         | 성능 평가 지표(metrics)를 stdout으로 출력                 |
| `TerminateOnNaN`        | `NaN` 손실이 발생했을 때 학습을 종료                      |
| `RemoteMonitor`         | 서버에 이벤트를 전송                                      |
| `CSVLogger`             | 에포크의 결과를 csv 파일로 전송                           |
| `Callback`              | 새로운 콜백을 제작할 수 있는 클래스                       |

<br>

<br>

## 2. 사용하기

콜백은 사용자가 학습 도중, 혹은 학습 후 돌려받고 싶은 모델의 피드백을 정의합니다. 따라서 사용자  별, 그리고 상황 별로 필요한 콜백이 다릅니다. 다행히 콜백의 기능들은 그 이름에서부터 기능을 쉽게 알 수 있습니다.

콜백 중에서도 기본이 되는 콜백, 혹은 자주 사용되는 콜백들부터 차근차근 알아보겠습니다.

<br>

### 2.1 History 및 콜백 공통 메서드

각각의 콜백 클래스들은 다음과 같은 공통된 메서드들을 보유하고 있습니다.

`on_batch_begin`, `on_batch_end`, `on_batch_end`, `on_epoch_begin`, `on_epoch_end`, `on_predict_batch_begin`, `on_predict_batch_end`, `on_predict_begin` ...

위의 메서드들은 학습 도중 어느 작업을 하던 중, 어느 시점에 사용자가 요청한 콜백을 점검할 것인지 결정합니다. 예를들어 `on_epoch_end`와 정확도가 `0.99` 이상일 때 학습을 중단하도록 콜백을 지정했다면, 한 에포크가 종료될 때마다 정확도가 `0.99` 이상이되는가를 점검 후 조건 만족 시 학습을 종료합니다.

`History` 클래스는 학습, 검증, 테스트 과정에서 측정되는 지표들을 저장하기 위해 사용합니다.

<br>

### 2.2 BaseLogger

베이스 로거(BaseLogger)는 에포크(epoch) 별 측정 지표(metrics)를 누적합니다. 콜백의 이름이 베이스 로거인 이유는 모든 케라스 모델들에 자동으로 적용되기 때문입니다. 따라서 `fit`과 같은 학습 메서드에 베이스 로거 콜백을 사용하라고 지시해줘야 할 필요가 없습니다. 로그는 `on_epoch_end` 시점에 `History` 객체 형태로 기록됩니다.

<br>

### 2.2.1 매개변수

```python
__init__(stateful_metrics=None)
```

- `stateful_metrics`

  이 매개변수에 기록한 Iterable(리스트 등)에 해당하는 측정 지표들은 기록하지 않습니다.

<br>

### 2.2.2 예시

`fit`과 같은 학습 메서드의 실행 결과를 임의의 변수에 저장한 후, 그 변수의 `history`를 호출합니다.

코드

```python
from __future__ import absolute_import, division, print_function, unicode_literals
import tensorflow as tf
from tensorflow import keras
import numpy as np

fashion_mnist = keras.datasets.fashion_mnist
(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()
class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal',
 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot']
 
train_images = train_images / 255.0
test_images = test_images / 255.0

model = keras.Sequential([
    keras.layers.Flatten(input_shape=(28, 28)),
    keras.layers.Dense(128, activation=tf.nn.relu),
    keras.layers.Dense(10, activation=tf.nn.softmax)
])

model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

train_his = model.fit(train_images, train_labels, epochs=5, callbacks=None)
print(train_his.history)
```

결과

```
{'loss': [0.5007445385138194, 0.37360614700714745, 0.3342456784168879, 0.31103399897416434, 0.2948230089247227], 'acc': [0.8250167, 0.8647, 0.8793167, 0.88591665, 0.89155]}
```

<br>

<br>

### 2.3 EarlyStopping

모니터링하는 지표가 성장을 멈추면 학습을 중단합니다. 적절하게 고려된 조기 중단(Early Stopping)은 모델 학습에 좋은 영향을 미치는 경우가 많습니다. 우리는 정확히 모델이 얼마나 학습해야 하는지 알 수 없습니다. 학습 회수가 늘어날 수록 학습 데이터셋과 검증 데이터셋에 대한 모델의 정답률은 올라갈 수 있습니다. 하지만 지나친 학습/검증 데이터 학습은 모델의 **일반화**에 악영향을 미칠 수 있습니다. 일반화란 모델이 학습하지 않은 데이터에 대한 정답율을 높히는 작업입니다.

쉽게 사용할 수 있는 조기 중단의 시점은 테스트 데이터셋에 대한 정확도가 감소하는 시점입니다. 이를 포착하기 위해 검증 데이터셋(validation dataset)의 개념이 도입됐습니다. 테스트 데이터셋을 학습의 측정 지표로 사용하는 것 또한 결국 학습 자체에 영향을 미치는 것이므로, 테스트 데이터셋을 완전히 격리하고 검증 데이터셋을 학습 도중의 측정 데이터셋으로 사용합니다. 이렇게 분리하여 검증 데이터셋에 대한 측정 지표(metric)는 성능이 향상되고 있음을 말해주지만, 테스트 데이터셋에 대한 지표가 하락하고 있는 상황을 과적합(Overfitting)이라고 합니다. 우리는 학습을 조기 중단하여 이러한 상황을 회피해야 합니다.

<br>

### 2.3.1 매개변수

```python
__init__(
    monitor='val_loss',
    min_delta=0,
    patience=0,
    verbose=0,
    mode='auto',
    baseline=None,
    restore_best_weights=False
)
```

- `monitor`

  모니터 할 지표를 지정합니다.

- `min_delta`

  지정한 지표의 성능이 향상 중이라고 여기는 최소 변화량을 지정합니다.

- `patience`

  `min_delta` 보다 작은 성장이 몇 회 반복되는 것까지 기다릴 것인지 지정합니다. 즉, `patience` 횟수 만큼 성장이 이루어지지 않는다면 학습을 중단합니다.

- `verbose`

  얼마나 자세히 로그를 보고할 것인가를 지정합니다.

- `mode`

  조기 중단을 측정하는 지표의 최소화를 목표로 하는지, 혹은 최대화를 목표로하는지 설정합니다. `"auto"`, `"min"`, `"max"` 세 가지 값 중 하나를 설정할 수 있습니다.

  - `min`

    지표가 감소하는 방향으로 학습하는 것으로 인식합니다.

  - `max`

    지표가 증가하는 방향으로 학습하는 것으로 인식합니다.

  - `auto`

    지표의 이름에 따라 자동으로 설정됩니다.

- `baseline`

  설정하는 기준값 이상으로 향상되지 않는다면, 학습을 조기 중단합니다.

- `restore_best_weights`

  매 에포크 마다 가장 성능이 좋았던 가중치를 복구하여 설정합니다. `False`일 경우 가장 마지막 스텝에서 계산해낸 가중치를 사용합니다.

### 2.3.2 예시

500 에포크 학습을 진행하는데, 3회의 에포크 동안 정확도(`acc`)에서 성능 향상이 없다면 학습을 조기 중단합니다.

코드

```python
from __future__ import absolute_import, division, print_function, unicode_literals
import tensorflow as tf
from tensorflow import keras
import numpy as np

fashion_mnist = keras.datasets.fashion_mnist
(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()
class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal',
 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot']
 
train_images = train_images / 255.0
test_images = test_images / 255.0

model = keras.Sequential([
    keras.layers.Flatten(input_shape=(28, 28)),
    keras.layers.Dense(128, activation=tf.nn.relu),
    keras.layers.Dense(10, activation=tf.nn.softmax)
])

model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

# 조기 중단 콜백을 설정합니다.
callback = tf.keras.callbacks.EarlyStopping(monitor='acc', patience=3)
# 학습 메서드인 fit을 사용하며, 콜백 매개변수에 위에서 설정한 콜백을 지정합니다.
model.fit(train_images, train_labels, epochs=500, callbacks=[callback])
```

결과

```
Epoch 50/500
60000/60000 [==============================] - 2s 26us/sample - loss: 0.1006 - acc: 0.9620
Epoch 51/500
60000/60000 [==============================] - 2s 26us/sample - loss: 0.0987 - acc: 0.9627
Epoch 52/500
60000/60000 [==============================] - 2s 26us/sample - loss: 0.0980 - acc: 0.9627
Epoch 53/500
60000/60000 [==============================] - 2s 25us/sample - loss: 0.0995 - acc: 0.9621
Epoch 54/500
60000/60000 [==============================] - 2s 25us/sample - loss: 0.0937 - acc: 0.9653
Epoch 55/500
60000/60000 [==============================] - 2s 26us/sample - loss: 0.0933 - acc: 0.9648
Epoch 56/500
60000/60000 [==============================] - 2s 26us/sample - loss: 0.0926 - acc: 0.9647
Epoch 57/500
60000/60000 [==============================] - 2s 25us/sample - loss: 0.0929 - acc: 0.9648
학습 종료
```

57 에포크 학습 후 조기 중단합니다.

<br>

### 2.4 LearningRateScheduler

모델 학습의 주요 파라미터(Hyper Parameter) 중 하나인 학습률(Learning Rate)을 동적으로 관리합니다. 학습률을 관리하는 것은 모델 학습을 최적화 하는 기법들 중 하나입니다. 주로 큰 값의 학습률로 학습을 시작하여 점차 줄여나아가는 형태로 관리합니다.

### 2.4.1 매개변수

```python
__init__(
    schedule,
    verbose=0
)
```

- `schedule`

  에포크의 인덱스를 입력값으로 취하며, 새로운 학습률을 반환하는 함수를 지정합니다.

- `verbose`

  `0`으로 설정할 시 아무런 피드백을 하지 않으며, `1`일 시 메세지를 업데이트 합니다.

### 2.4.2 예시

아래의 `scheduler` 함수는 `10` 에포크까지는` 0.001`의 학습률을 유지하다가, `11` 에포크 부터는 기하급수적으로 감소합니다.

```python
def scheduler(epoch):
  if epoch < 10:
    return 0.001
  else:
    return 0.001 * tf.math.exp(0.1 * (10 - epoch))

callback = tf.keras.callbacks.LearningRateScheduler(scheduler)
model.fit(data, labels, epochs=100, callbacks=[callback],
          validation_data=(val_data, val_labels))
```

<br>

### 2.5 ReduceLROnplateau

측정 수단(metric)의 성장을 체크하여, `patience` 값 동안 성장이 멈추면 학습률을 `factor` 만큼 감소시킵니다.

### 2.5.1 매개변수

```python
__init__(
    monitor='val_loss',
    factor=0.1,
    patience=10,
    verbose=0,
    mode='auto',
    min_delta=0.0001,
    cooldown=0,
    min_lr=0,
    **kwargs
)
```

- `monitor`

  모니터링 할 지표를 지정합니다.

- `factor`

  기존 조정할 학습률에 `factor` 를 적용하여 새로운 학습률을 생성합니다.

  `새 학습률 = (기존 학습률) * factor`

- `patience`

  몇 회의 에포크 동안 성능 향상이 없을 시 학습률을 감소시킬 것인지 결정합니다.

- `verbose`

  `0`으로 설정할 시 아무런 피드백을 하지 않으며, `1`일 시 메세지를 업데이트 합니다.

- `mode`

  조기 중단을 측정하는 지표의 최소화를 목표로 하는지, 혹은 최대화를 목표로하는지 설정합니다. `"auto"`, `"min"`, `"max"` 세 가지 값 중 하나를 설정할 수 있습니다.

  - `min`

    지표가 감소하는 방향으로 학습하는 것으로 인식합니다.

  - `max`

    지표가 증가하는 방향으로 학습하는 것으로 인식합니다.

  - `auto`

    지표의 이름에 따라 자동으로 설정됩니다.

- `min_delta`

  학습률을 감소시키기 전, 최적 상태임을 판단하는데 사용되는 임계치입니다.

- `cooldown`

  학습률 감소 후, 몇 회의 에포크 동안 학습률 감소 작업을 진행하지 않고 대기할 것인지 결정합니다.

- `min_lr`

  학습률의 최소값을 설정합니다.

### 2.5.2 예시

평가 지표 중 정확도를 참고하여 학습률을 감소시킵니다.

코드

```python
reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='acc', verbose=1,
                                                 factor=0.2, patience=5, min_lr=0.001)
model.fit(train_images, train_labels, epochs=500, callbacks=[reduce_lr])
```

결과

```
Epoch 106/500
60000/60000 [==============================] - 2s 26us/sample - loss: 0.0494 - acc: 0.9814
Epoch 107/500
60000/60000 [==============================] - 2s 27us/sample - loss: 0.0493 - acc: 0.9822
Epoch 108/500
59328/60000 [============================>.] - ETA: 0s - loss: 0.0500 - acc: 0.9813
Epoch 00108: ReduceLROnPlateau reducing learning rate to 0.001.
60000/60000 [==============================] - 2s 27us/sample - loss: 0.0502 - acc: 0.9812
Epoch 109/500
60000/60000 [==============================] - 2s 26us/sample - loss: 0.0505 - acc: 0.9815
```

학습 도중, 108 에포크에서 학습률이 0.001로 감소했습니다.

<br>

### 2.6 ModelCheckpoint

매 에포크마다 모델을 저장합니다.

`filepath` can contain named formatting options, which will be filled the value of `epoch` and keys in `logs` (passed in `on_epoch_end`).

For example: if `filepath` is `weights.{epoch:02d}-{val_loss:.2f}.hdf5`, then the model checkpoints will be saved with the epoch number and the validation loss in the filename.



This callback will save your model as a checkpoint file (in `hdf5` format) to disk after each successful epoch. You can actually set the output file to be dynamically named based on the epoch. You can also write either the loss value or accuracy value as part of the log’s file name. This is especially handy for models where epochs take an extremely long time, or if you’re running them on AWS spot instances and the spot instance price rises above your maximum bid.

![img](https://miro.medium.com/max/60/1*6OVpCFwlXmBQYio4yiLQ6g.png?q=20)

![img](https://miro.medium.com/max/2508/1*6OVpCFwlXmBQYio4yiLQ6g.png)

Plot of accuracy (top) and loss (bottom) over 100 epochs training an RNN

<br>

### 2.6.1 매개변수

```python
__init__(
    filepath,
    monitor='val_loss',
    verbose=0,
    save_best_only=False,
    save_weights_only=False,
    mode='auto',
    save_freq='epoch',
    load_weights_on_restart=False,
    **kwargs
)
```

- `filepath`: string, path to save the model file.
- `monitor`: quantity to monitor.
- `verbose`: verbosity mode, 0 or 1.
- `save_best_only`: if `save_best_only=True`, the latest best model according to the quantity monitored will not be overwritten.
- `mode`: one of {auto, min, max}. If `save_best_only=True`, the decision to overwrite the current save file is made based on either the maximization or the minimization of the monitored quantity. For `val_acc`, this should be `max`, for `val_loss` this should be `min`, etc. In `auto` mode, the direction is automatically inferred from the name of the monitored quantity.
- `save_weights_only`: if True, then only the model's weights will be saved (`model.save_weights(filepath)`), else the full model is saved (`model.save(filepath)`).
- `save_freq`: `'epoch'` or integer. When using `'epoch'`, the callback saves the model after each epoch. When using integer, the callback saves the model at end of a batch at which this many samples have been seen since last saving. Note that if the saving isn't aligned to epochs, the monitored metric may potentially be less reliable (it could reflect as little as 1 batch, since the metrics get reset every epoch). Defaults to `'epoch'`
- `load_weights_on_restart`: Whether the training should restore the model. If True, the model will attempt to load the checkpoint file from `filepath` at the start of `model.fit()`. This saves the need of manually calling `model.load_weights()` before `model.fit(). In multi-worker distributed training, this provides fault-tolerance and loads the model automatically upon recovery of workers. The callback gives up loading if the filepath does not exist, and raises ValueError if format does not match. Defaults to False.
- `**kwargs`: Additional arguments for backwards compatibility. Possible key is `period`.

<br>

### 2.7 기타 콜백들

- `TensorBoard`

  '3.4.1 Tensorboard' 에서 자세히 다루겠습니다.

  This is probably the coolest of all the out-of-the-box callbacks. By using a TensorBoard callback, logs will be written to a directory that you can then examine with TensorFlow’s excellent TensorBoard visualization tool. It even works (to an extent) if you’re using a backend other than TensorFlow, like Theano, or CNTK (if you’re a glutton for punishment).

- `LambdaCallback`

  If none of the techniques above fit what you’re trying to achieve, you can create your own callback. If you just want to create a basic one, you can use LambdaCallback. This allows you to trigger events when an epoch, batch, or training process begins or ends.

  If you want to create something a little more complex, you can create your own callback by inheriting from the `keras.callbacks.Callback` class. This is only for those who truly want low-level control over how a callback is executed. You may also want to create your own callback if you’re implementing some custom logic that’s not available in the existing callbacks.

- `Callback`

- `TerminateOnNaN`

- `RemoteMonitor`

- `ProgbarLoggaer`

- `CSVLogger`




